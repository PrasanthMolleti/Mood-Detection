{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fab50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import uuid\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b955d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = [\"sad\", \"happy\", \"angry\"]\n",
    "num_img = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_path = os.path.join(\".\", \"Data\", \"Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_name = \"ssd_mobnet_emotion\"\n",
    "Pretrained_model_name = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\"\n",
    "Pretrained_model_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1850e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"Images_path\": os.path.join(\".\", \"Data\", \"Images\"),\n",
    "    \"Labelled_images_path\": os.path.join(\".\", \"Data\", \"Labelled Images\"),\n",
    "    \"Train_images_path\": os.path.join(\".\", \"Data\", \"Train_images\"),\n",
    "    \"Test_images_path\": os.path.join(\".\", \"Data\", \"Test_images\"),\n",
    "    \"Protoc_path\": os.path.join(\".\", \"Models\", \"Protoc\"),\n",
    "    \"Models_path\": os.path.join(\".\", \"Models\"),\n",
    "    \"Pretrained_model_path\": os.path.join(\".\", \"Models\", \"pretrained_model\"),\n",
    "    \"Output_path\": os.path.join(\".\", \"Models\", MODEL_name, \"Export\"),\n",
    "    \"Miscellaneous_path\" : os.path.join('.', 'Miscellameous')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f34b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(Img_path):\n",
    "    if os.name == \"nt\":\n",
    "        !mkdir {Img_path}\n",
    "    if os.name == \"posix\":\n",
    "        !mkdir -p {Img_path}\n",
    "for label in img_labels:\n",
    "    label_path = os.path.join(Img_path, label)\n",
    "    if not os.path.exists(label_path):\n",
    "        if os.name == \"nt\":\n",
    "            !mkdir {label_path}\n",
    "        if os.name == \"posix\":\n",
    "            !mkdir -p {label_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8523c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_capture(img_labels, Img_path, num_img):\n",
    "    for img_label in img_labels:\n",
    "        capture_device = cv2.VideoCapture(0)\n",
    "        print(f\"Collecting images for {img_label}\")\n",
    "        time.sleep(6)\n",
    "        for img in range(num_img):\n",
    "            print(f\"Collecting image no.{img+1}\")\n",
    "            retina, frame = capture_device.read()\n",
    "            img_name = os.path.join(\n",
    "                Img_path, img_label + \".\" + f\"{str(uuid.uuid1())}.jpg\"\n",
    "            )\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            time.sleep(3)\n",
    "\n",
    "            ## Manual Exit Sequence For the capture using the 'q' key\n",
    "            if (cv2.waitKey(1) & 0xFF) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    capture_device.release()\n",
    "    cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_labelling():\n",
    "    LabelImg_path = os.path.join(\".\", \"Data\", \"Labelled Images\")\n",
    "\n",
    "    if not os.path.exists(LabelImg_path):\n",
    "        if os.name == \"nt\":\n",
    "            !mkdir {LabelImg_path}\n",
    "        if os.name == \"posix\":\n",
    "            !mkdir -p {LabelImg_path}\n",
    "\n",
    "    ## Installation setup\n",
    "    if os.name == \"posix\":\n",
    "        !cd {LabelImg_path} && make qt5py3\n",
    "    elif os.name == \"nt\":\n",
    "        !cd {LabelImg_path} && pyrcc5 -o libs/resources.py resources.qrc\n",
    "\n",
    "    ## Opening the labelImg app\n",
    "    !cd {LabelImg_path} && python labelImg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLIT THE IMAGES INTO TRAIN AND TEST DATA FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in file_paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == \"nt\":\n",
    "            !mkdir {path}\n",
    "        if os.name == \"posix\":\n",
    "            !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce445182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78162f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20895434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading Tensor Flow Object Detection API\n",
    "if not os.path.exists(os.path.join(file_paths[\"Models_path\"], \"object-detection-api\")):\n",
    "    ! mkdir {os.path.join(file_paths['Models_path'], 'object-detection-api')}\n",
    "    !git clone https://github.com/tensorflow/models {os.path.join(file_paths['Models_path'], 'object-detection-api')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing Object Detection\n",
    "\n",
    "if os.name == \"posix\":\n",
    "    !apt-get install protobuff-compiler\n",
    "    !cd Models/object-detection-api/research && protoc object_detection/protos/*.proto --python_out. && cp object_detection/packages/tf2/setup.py\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    url = \"https://github.com/protocolbuffers/protobuf/releases/download/v22.0/protoc-22.0-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-22.0-win64.zip {file_paths['Protoc_path']}\n",
    "    ! cd {file_paths['Protoc_path']} && tar -xf protoc-22.0-win64.zip\n",
    "    os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\n",
    "        os.path.join(file_paths[\"Protoc_path\"], \"bin\")\n",
    "    )\n",
    "    !cd Models/object-detection-api/research && protoc object_detection/protos/*.proto -- python_out=. && copy object_detection/packages/tf2/setup.py\n",
    "    ! cd Models/object-detection-api/research/slim && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99051f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Object Detection Setup Verification\n",
    "Verification_script = os.path.join(\n",
    "    file_paths[\"Models_path\"],\n",
    "    \"object-detection-api\",\n",
    "    \"research\",\n",
    "    \"object_detection\",\n",
    "    \"builders\",\n",
    "    \"model_builder_tf2_test.py\",\n",
    ")\n",
    "!python {Verification_script}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37608b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !wget {Pretrained_model_url}\n",
    "    !mv {Pretrained_model_name + '.tar.gz'} {file_paths['Pretrained_model_path']}\n",
    "    !cd {file_paths['Pretrained_model_path']} && tar -zxvf {Pretrained_model_name + '.tar.gz'}\n",
    "\n",
    "if os.name == 'nt':\n",
    "    wget.download(Pretrained_model_url)\n",
    "    !move {Pretrained_model_name + '.tar.gz'} {file_paths['Pretrained_model_path']}\n",
    "    !cd {file_paths['Pretrained_model_path']} && tar -zxvf {Pretrained_model_path + '.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed755ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name' : 'happy', 'id' : 0},{'name' : 'sad', 'id' : 1},{'name' : 'angry', 'id' : 2}] \n",
    "with open(file_paths['Miscellaneous_path'], 'w') as file:\n",
    "    for label in labels:\n",
    "        file.write('item { \\n')\n",
    "        file.write(f'\\tname:\\{label['name']}\\n')\n",
    "        file.write(f'\\tid:{label['id']}\\n')\n",
    "        file.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "    !tar -zxvf {ARCHIVE_FILES}\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e979f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1507db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config:\n",
    "    config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "    pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "    with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "        text_format.Merge(proto_str, pipeline_config)  \n",
    "    \n",
    "    pipeline_config.model.ssd.num_classes = len(labels)\n",
    "    pipeline_config.train_config.batch_size = 4\n",
    "    pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "    pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "    pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "    pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "    pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "    pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n",
    "\n",
    "    config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "    with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "        f.write(config_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "def training_():\n",
    "    TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "    ! python {TRAINING_SCRIPT} --model_dir={paths['CHECKPOINT_PATH']} --pipeline_config_path={files['PIPELINE_CONFIG']} --num_train_steps=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949778c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "def testing_():\n",
    "    ! python {TRAINING_SCRIPT} --model_dir={paths['CHECKPOINT_PATH']} --pipeline_config_path={files['PIPELINE_CONFIG']} --checkpoint_dir={paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9607dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_()\n",
    "testing_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0031be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
